{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The PSHA Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1209,
     "status": "ok",
     "timestamp": 1725990398055,
     "user": {
      "displayName": "Jack Wesley Baker",
      "userId": "04310741851728712835"
     },
     "user_tz": 420
    },
    "id": "AQcN5-tYvzcK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1725990398056,
     "user": {
      "displayName": "Jack Wesley Baker",
      "userId": "04310741851728712835"
     },
     "user_tz": 420
    },
    "id": "5sJ8HhgCg2bz"
   },
   "outputs": [],
   "source": [
    "# IN THE CASE OF SAVING THE FUNCTION FILES IN THE GOOGLE DRIVE\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# import sys\n",
    "# sys.path.append('/content/drive/MyDrive/Colab Notebooks')\n",
    "\n",
    "# import GMM_Functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qOWVaZ0mACsn"
   },
   "source": [
    "## Import the function files from a GitHub Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 913,
     "status": "ok",
     "timestamp": 1725990398962,
     "user": {
      "displayName": "Jack Wesley Baker",
      "userId": "04310741851728712835"
     },
     "user_tz": 420
    },
    "id": "Ai-kK4FbNGWJ",
    "outputId": "a6f3ff8e-8d40-4a49-8291-69f356120959"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CEE_288_TEST'...\n",
      "remote: Enumerating objects: 3, done.\u001b[K\n",
      "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
      "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
      "remote: Total 3 (delta 0), reused 3 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (3/3), 4.83 KiB | 4.83 MiB/s, done.\n",
      "/content/CEE_288_TEST\n"
     ]
    }
   ],
   "source": [
    "# Repository must be public\n",
    "!git clone https://github.com/gcalana/CEE_288_TEST.git\n",
    "%cd CEE_288_TEST\n",
    "import GMM_Functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJkz6BBaTL0M"
   },
   "source": [
    "## The PSHA Calculation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1E8FdJPruEZr"
   },
   "source": [
    "At a basic level, PSHA is composed of five steps:\n",
    "\n",
    "1. Specify the ground-motion intensity measure (IM) of interest (Section 4.2).\n",
    "2. Specify the site properties that help predict ground-motion intensity (Section 4.5.3).\n",
    "3. Compute the locations, characteristics, and occurrence rates of all rupture scenarios capable of producing damaging ground motions (Chapter 3).\n",
    "4. Predict the resulting distribution of ground-motion intensity as a function of the site characteristics and each rupture scenario’s properties (Chapters 4 and 5).\n",
    "5. Consider all possible ruptures, and uncertainty in resulting ground-motion intensity (Figure 6.1 and Equation 6.1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pf7YvcfuhPZj"
   },
   "source": [
    "## Example from section 6.3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1alxkz1wvghH"
   },
   "source": [
    "## 1. Specify the gound-motion intensity measure (IM) of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1725990398962,
     "user": {
      "displayName": "Jack Wesley Baker",
      "userId": "04310741851728712835"
     },
     "user_tz": 420
    },
    "id": "JRUTKUJ7vpFx"
   },
   "outputs": [],
   "source": [
    "# Some initial user-defined parameters\n",
    "x = np.logspace(np.log10(0.001), np.log10(2), 100)  # IM values to consider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7WVl1nowHKv"
   },
   "source": [
    "## 2. Specify the site properties that help predict ground-motion intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1725990398962,
     "user": {
      "displayName": "Jack Wesley Baker",
      "userId": "04310741851728712835"
     },
     "user_tz": 420
    },
    "id": "uGXiQU02vyvY"
   },
   "outputs": [],
   "source": [
    "# Define combine rupture and site parameters into a dictionary\n",
    "T = 1 # Period of interest\n",
    "R = 10 # Horizontal distance from top of rupture measured perpendicular to fault strike (km)\n",
    "Rrup = R # Closest distance (km) to the rupture plane\n",
    "Rjb = R # Joyner-Boore distance (km); closest distance (km) to surface projection of rupture plane\n",
    "rup = {\n",
    "    'Fault_Type': 1,  # 1 is strike slip\n",
    "    'Vs30': 500, # Shear wave velocity averaged over top 30 m in m/s\n",
    "    'R': 10,\n",
    "    'Ztor': 0, # Rupture depth\n",
    "    'delta': 90, # The angle between the fault and a horizontal plane (90 = vertical fault)\n",
    "    'rupLambda': 0, # The direction a hanging wall block moves during rupture (0 means left lateral motion of the hanging wall relative to the footwall)\n",
    "    'Z10': 999, # Basin depth (km); depth from the groundsurface to the 1 km/s shear wave horizon\n",
    "    'Fhw': 0, # Hanging wall flag (=1 for hanging wall, = 0 for foot wall)\n",
    "    'FVS30': 0, # 0 for Vs30 is inferred from geology, 1 for measured Vs30,\n",
    "    'region': 1, # 0 for global (incl. Taiwan), 1 for California, 2 for Japan, 3 for China, 4 for Italy , 5 for Turkey\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-fCYZsN3cAl"
   },
   "source": [
    "## 3. Compute the locations, characteristics, and occurrence rates of all rupture scenarios capable of producing damaging ground motions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6mEpNsN5NF8"
   },
   "source": [
    "$$ λ(IM>im) = ΣP(IM>im | rupᵢ, site)λ(rupᵢ) $$\n",
    "`λ(IM>im) is the occurance rate of ground motions with IM greater than im`\n",
    "* λ(rupᵢ) = Exceedance rate of earthquake for each M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tinzlrwI4xef"
   },
   "source": [
    "### Gutenberg-Richter Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MSrT_fM5srM"
   },
   "source": [
    "Gutenberg and Richter (1944) proposed a linear relationship between magnitude and the logarithmic of the number of earthquakes of that given magnitude. In subsequent publications, the same log-linear relationship has been adopted to represent the total number of events per year with a magnitude greater than or equal to a particular value:\n",
    "\n",
    "$$ \\log_{10}N(M\\ge m) = a - bm $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWlDEr-15-P9"
   },
   "source": [
    "The parameter b is known as the Gutenberg–Richter b-value, and Gutenberg and Richter (1944) found this b-value to be close to unity in their original study.20 Over the decades since their original contribution, many more analyses have confirmed that it is rare for this b-value to differ much from unity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWYmDp2h6Al_"
   },
   "source": [
    "This equation not directly used in practice for two main reasons. First, the expression is unbounded and implies a finite rate of occurrence of earthquakes of any magnitude, including physically impossible events. Second, it is possible to define the total activity rate only for magnitudes that are at least as large as the level of completeness for a given seismicity catalog (see Section 3.3.5). The modern equivalent of the Gutenberg–Richter distribution is the doubly bounded exponential distribution (Cornell and Vanmarcke, 1969) whose PDF is presented as:\n",
    "\n",
    "$$ f_M(m) = \\frac{βe^{[-β(m-m_{\\text{min}})]}}{1-e^{[-β(m_{\\text{max}}-m_{\\text{min}})]}} $$\n",
    "\n",
    "where\n",
    "$$ m_{min} ≤ m ≤ m_{max} $$ and $$ β = ln(10)b$$\n",
    "\n",
    "and the CDF of the doubly bounded exponential distribution is\n",
    "\n",
    "$$ F_M{(m)} = \\frac{1 - e^{[-β(m-m_{\\text{min}})]}}{1-e^{[-β(m_{\\text{max}}-m_{\\text{min}})]}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GoVPQQWE5pYC"
   },
   "source": [
    "Annual rate of exceedance for the bounded Gutenberg-Richter distribution is:\n",
    "\n",
    "$$ λ(M≥m) = λ(M≥m_{min})(1-F_M(m)) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIUJTPQj6wjV"
   },
   "source": [
    "From Table 3.5\n",
    "$$ b = 1 $$\n",
    "$$ β = ln(10)b = 2.302585093 $$\n",
    "$$ m_{min} = 5.0 $$\n",
    "$$ m_{max} = 8.0 $$\n",
    "$$ λ(M≥m_{min}) = 0.05 $$\n",
    "This means that on average, an event with a magnitude of at lear M = 5.0 occurs every 20 years."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 498,
     "status": "ok",
     "timestamp": 1725990399456,
     "user": {
      "displayName": "Jack Wesley Baker",
      "userId": "04310741851728712835"
     },
     "user_tz": 420
    },
    "id": "fqBP8k_08Qgm",
    "outputId": "d1ea7643-2960-4826-d014-390cf91a16c0"
   },
   "outputs": [],
   "source": "# Earthquake magnitude range\nm_range = list(np.arange(5,8.2, 0.2))\nprint(m_range)"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1725990399457,
     "user": {
      "displayName": "Jack Wesley Baker",
      "userId": "04310741851728712835"
     },
     "user_tz": 420
    },
    "id": "uA9l8zA49CGj",
    "outputId": "9c78a2fb-b287-4b2f-c7cf-569357afb4e0"
   },
   "outputs": [],
   "source": "# Note, m_vals are mid-points of the discretized intervals (not lower bounds)\nm_vals_list = []\nfor index, elem in enumerate(m_range):\n    if index == len(m_range)-1:\n      break\n    mid = (m_range[index] + m_range[index+1])/2\n    m_vals_list.append(mid)\nm_vals = np.array(m_vals_list)\nprint(m_vals)"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1725990399457,
     "user": {
      "displayName": "Jack Wesley Baker",
      "userId": "04310741851728712835"
     },
     "user_tz": 420
    },
    "id": "axMUUMFZ_Owd",
    "outputId": "6e7d00b0-6e7f-4712-f674-fd37783dee46"
   },
   "outputs": [],
   "source": "m_min = 5\nm_max = 8\nbeta = np.log(10)\nlambda_m = []\nmin_rate = 0.05\nfor m in m_range:\n  fm = (1 - np.exp(-beta*(m - m_min)))/(1-np.exp(-beta*(m_max-m_min)))\n  lambda_m.append(min_rate * (1-fm))\n\n# Rate of exceedance\nlambda_m.pop()\nprint(lambda_m)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emXhrURhdejf"
   },
   "source": [
    "## 4) Predict the resulting distribution of ground-motion intensity as a function of the site characteristics and each rupture scenario’s properties (Chapters 4 and 5) & 5) Consider all possible ruptures, and uncertainty in resulting ground-motion intensity (Figure 6.1 and Equation 6.1)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1725990399457,
     "user": {
      "displayName": "Jack Wesley Baker",
      "userId": "04310741851728712835"
     },
     "user_tz": 420
    },
    "id": "pp5Au4lKddDI"
   },
   "outputs": [],
   "source": "# Compute PSHA, with rupture rates for each M precomputed\n\n# Created by Jack Baker\n# Translated by AI\n\n# INPUTS\n# lambda_m      exceedance rate of EQs for each M\n# m_vals        values of M corresponding to lambda_m\n# x             IM values of interest\n# x_example     example IM value for table\n# rup           data structure with rupture and site parameters\n# gmpe_flag      =1 for BJF97, =2 for CY14\n\ndef fn_psha_given_m_lambda(lambda_m, m_vals, t, x, x_example, rup, gmpe_flag):\n    # Compute PSHA, with rupture rates for each M precomputed\n\n    # Find occurrence rates from exceedance rates\n    lambda_occur = np.concatenate((np.diff(lambda_m) * -1, [lambda_m[-1]]))\n\n    # Initialize dictionaries for results\n    lambda_result = {'x': [], 'example': []}\n    disagg = {'all': np.zeros((len(x), len(m_vals)))}\n\n    # p(exceeding each x threshold value | M)\n    for j in range(len(x)):\n        p_given_m = np.zeros(len(m_vals))\n        for i in range(len(m_vals)):\n            sa, sigma = f.gmm_eval(t, m_vals[i], rup, gmpe_flag)\n            p_given_m[i] = 1 - norm.cdf(np.log(x[j]), np.log(sa), sigma)\n\n        lambda_result['x'].append(np.sum(lambda_occur * p_given_m))\n        disagg['all'][j, :] = (lambda_occur * p_given_m) / lambda_result['x'][j]\n\n    # calcs for example IM case\n    p_ex = np.zeros(len(m_vals))\n    for i in range(len(m_vals)):\n        sa, sigma = f.gmm_eval(t, m_vals[i], rup, gmpe_flag)\n        p_ex[i] = 1 - norm.cdf(np.log(x_example), np.log(sa), sigma)\n\n    example_output = np.column_stack((np.arange(1, len(m_vals)+1), m_vals, lambda_occur, p_ex, lambda_occur * p_ex))\n    lambda_result['example'].append(np.sum(lambda_occur * p_ex))\n    disagg['example'] = (lambda_occur * p_ex) / lambda_result['example']\n    disagg['m_bar'] = np.sum(m_vals * disagg['example'])\n\n    # disagg conditional on occurrence for example IM case\n    x_inc = x_example * 1.02  # do computations at an increment on x\n    p_inc = np.zeros(len(m_vals))\n    for i in range(len(m_vals)):\n        sa, sigma = f.gmm_eval(t, m_vals[i], rup, gmpe_flag)\n        p_inc[i] = 1 - norm.cdf(np.log(x_inc), np.log(sa), sigma)\n    lambda_inc = np.sum(lambda_occur * p_inc)\n    disagg['equal'] = ((lambda_occur * p_ex) - (lambda_occur * p_inc)) / (lambda_result['example'] - lambda_inc)\n    disagg['equal_m_bar'] = np.sum(m_vals * disagg['equal'])\n\n    # disaggs with epsilon\n    delta_eps = 1  # final binning\n    eps_vals = np.arange(-3, 3 + delta_eps, delta_eps)  # epsilon bins\n\n    delta_eps_fine = 0.1  # initial finer binning\n    eps_vals_fine = np.arange(-3.5, 3.5 + delta_eps_fine, delta_eps_fine)  # midpoints of bins\n    p_eps = norm.pdf(eps_vals_fine) * delta_eps_fine  # estimate PDF using a PMF with discrete epsilon increments\n    lambda_m_and_eps = np.outer(lambda_occur, p_eps)  # rate of events with a given magnitude and epsilon\n\n    ind = np.zeros((len(m_vals), len(eps_vals_fine)), dtype=bool)\n    for i in range(len(m_vals)):\n        sa, sigma = f.gmm_eval(t, m_vals[i], rup, gmpe_flag)\n        ind[i, :] = (np.log(sa) + eps_vals_fine * sigma > np.log(x_example))  # indicator that the M/epsilon value causes IM > x_example\n    exceed_rates_fine = ind * lambda_m_and_eps  # rates of given M/epsilon values exceeding IM\n    lambda_exceed = np.sum(exceed_rates_fine)  # this is close to lambda.example, but may differ by a few percent due to epsilon discretization\n\n    # compute mean epsilon\n    eps_deagg = np.sum(exceed_rates_fine, axis=0) / np.sum(exceed_rates_fine)\n    disagg['eps_bar'] = np.sum(eps_vals_fine * eps_deagg)\n\n    # aggregate results to coarser epsilon bins\n    exceed_rates = np.zeros((len(m_vals), len(eps_vals)))\n    for j in range(len(eps_vals)):\n        idx = (eps_vals_fine >= (eps_vals[j] - delta_eps / 2)) & (eps_vals_fine < (eps_vals[j] + delta_eps / 2))\n        exceed_rates[:, j] = np.sum(exceed_rates_fine[:, idx], axis=1)\n\n    disagg['eps_vals'] = eps_vals  # return bin midpoints\n    disagg['m_eps'] = exceed_rates / lambda_exceed  # magnitude and epsilon disaggregation\n    disagg['eps'] = np.sum(exceed_rates, axis=0) / lambda_exceed  # epsilon disaggregation\n\n    disagg['equal_m_bar'] = np.sum(m_vals * disagg['equal'])\n\n    return lambda_result, example_output, disagg"
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 2700,
     "status": "ok",
     "timestamp": 1725990402145,
     "user": {
      "displayName": "Jack Wesley Baker",
      "userId": "04310741851728712835"
     },
     "user_tz": 420
    },
    "id": "hjuyoUDw304Q"
   },
   "outputs": [],
   "source": "x_example = 0.2  # example values for table\ngmpe_flag = 1\n# Compute the PSHA given M and lambda\nlambda_, example_output, disagg = fn_psha_given_m_lambda(lambda_m, m_vals, T, x, x_example, rup, gmpe_flag)\n\nx_example2 = 0.5  # output results for a second threshold\nlambda2, example_output2, disagg2 = fn_psha_given_m_lambda(lambda_m, m_vals, T, x, x_example2, rup, gmpe_flag)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdHl9KXGBFTD"
   },
   "source": [
    "## PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1725990402146,
     "user": {
      "displayName": "Jack Wesley Baker",
      "userId": "04310741851728712835"
     },
     "user_tz": 420
    },
    "id": "bCU1Y2hDbNFo"
   },
   "outputs": [],
   "source": "# Plot set up\nplt.close('all')\nplt.rcParams.update({'font.size': 12})\ncolor_spec = [\n    [56 / 255, 95 / 255, 150 / 255],\n    [207 / 255, 89 / 255, 33 / 255],\n    [158 / 255, 184 / 255, 219 / 255],\n]\n\n# Plotting parameters\nfigure_axis_limits = [0.05, max(x), 1 / 0.99e-5, 1e-1]\nfigure_x_tick_vals = [0.05, 0.1, 0.5, 1, 2]\n\nim_label = 'SA(1 s)'\naxis_label = 'Spectral Acceleration, SA(1 s) [g]'"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "executionInfo": {
     "elapsed": 1261,
     "status": "ok",
     "timestamp": 1725990464121,
     "user": {
      "displayName": "Jack Wesley Baker",
      "userId": "04310741851728712835"
     },
     "user_tz": 420
    },
    "id": "305aOlKwZpMl",
    "outputId": "bef15212-b33b-4682-e728-0dfb01f73b41"
   },
   "outputs": [],
   "source": "# Hazard curve plot\nfig, ax = plt.subplots()\nax.loglog(x, lambda_['x'], '-', linewidth=2, color=color_spec[0])\nax.plot(x_example, lambda_['example'], 'o', color=color_spec[0])\nax.plot(x_example2, lambda2['example'], 'o', color=color_spec[0])\n\n# Annotate text results for example cases\ntext1 = f\"$\\lambda$({im_label} > {x_example} g) = {lambda_['example'][0]:.3g}\"\ntext2 = f\"$\\lambda$({im_label} > {x_example2} g) = {lambda2['example'][0]:.3g}\"\nax.text(x_example * 1.1, lambda_['example'][0] * 1.2, text1, fontsize=8)\nax.text(x_example2 * 1.1, lambda2['example'][0] * 1.2, text2, fontsize=8)\n\nplt.xlabel(axis_label)\nplt.ylabel('Annual rate of exceedance, $\\lambda$')\nax.set_xscale('log')\nplt.xlim([0.05, 2])\nplt.xticks([0.05, 0.1, 0.5, 1,  2], ['0.05', '0.1', '0.5', '1', '2'])\n\n\nplt.show()"
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1725990405592,
     "user": {
      "displayName": "Jack Wesley Baker",
      "userId": "04310741851728712835"
     },
     "user_tz": 420
    },
    "id": "hl0CUS6i_w1F"
   },
   "outputs": [],
   "source": "# Output a subset of the hazard curve for use in a table\nim_small = np.array([1e-3] + list(np.arange(0.1, 1.1, 0.1)))\nrates_small = np.exp(interp1d(np.log(x), np.log(lambda_['x']), kind='linear', fill_value='extrapolate')(np.log(im_small)))\nhaz_table = np.column_stack((im_small, rates_small))"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 601
    },
    "executionInfo": {
     "elapsed": 2943,
     "status": "ok",
     "timestamp": 1725990408529,
     "user": {
      "displayName": "Jack Wesley Baker",
      "userId": "04310741851728712835"
     },
     "user_tz": 420
    },
    "id": "wSqWCYHl_ymS",
    "outputId": "a3fbd18f-174d-4687-985e-a2c41aa3520a"
   },
   "outputs": [],
   "source": "# Disaggregation plot\nplt.figure(figsize=(10, 6))\nplt.subplot(1, 2, 1)\nplt.bar(m_vals, disagg['example'], width=0.2, color=color_spec[2], edgecolor='black')\nplt.plot([disagg['m_bar'], disagg['m_bar']], [0, 1], ':k', linewidth=2)\nplt.xlabel('Magnitude, M')\nplt.ylabel(f'P(m | {im_label} > {x_example} g)')\nplt.axis([5, 8, 0, 0.2])\n\nplt.subplot(1, 2, 2)\nplt.bar(m_vals, disagg2['example'], width=0.2, color=color_spec[2], edgecolor='black')\nplt.plot([disagg2['m_bar'], disagg2['m_bar']], [0, 1], ':k', linewidth=2)\nplt.xlabel('Magnitude, M')\nplt.ylabel(f'P(m | {im_label} > {x_example2} g)')\n# plt.axis([5, 8, 0, 0.2])\nplt.ylim([0, 0.2])\nplt.xlim([4,8])\n\nplt.tight_layout()"
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1725990408529,
     "user": {
      "displayName": "Jack Wesley Baker",
      "userId": "04310741851728712835"
     },
     "user_tz": 420
    },
    "id": "foblqStF__o3"
   },
   "outputs": [],
   "source": "m_bar = [disagg['m_bar'], disagg2['m_bar']]\n\n# Tabulate output\ndisagg_table = np.column_stack((m_vals, disagg['example'], disagg2['example']))\n\n# Metrics to evaluate calculations and figure\n# Interpolate IM with given rate\nrate_targ = 1 / 1000\nim_targ = np.exp(interp1d(np.log(rates_small), np.log(im_small), kind='linear', fill_value='extrapolate')(np.log(rate_targ)))\n\n# Manual log interpolation\nln_im_manual = ((np.log(0.2) - np.log(0.3)) * (np.log(1E-3) - np.log(6.81E-4))) / (np.log(2.7E-3) - np.log(6.81E-4)) + np.log(0.3)\nim_manual = np.exp(ln_im_manual)\n\n# Hazard curves slope\nim_slope = [0.2, 0.3]\nrate_slope = np.exp(interp1d(np.log(x), np.log(lambda_['x']), kind='linear', fill_value='extrapolate')(np.log(im_slope)))\nk_est = - (np.log(rate_slope[0]) - np.log(rate_slope[1])) / (np.log(im_slope[0]) - np.log(im_slope[1]))\nk0_est = rate_slope[0] / np.exp(-k_est * np.log(im_slope[0]))\nlambda_power_law = k0_est * np.exp(-k_est * np.log(x))\n\n# Hazard curve derivative\nd_lambda = -np.diff(np.concatenate((rates_small, [0])))"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 601
    },
    "executionInfo": {
     "elapsed": 2417,
     "status": "ok",
     "timestamp": 1725990410938,
     "user": {
      "displayName": "Jack Wesley Baker",
      "userId": "04310741851728712835"
     },
     "user_tz": 420
    },
    "id": "RmViQYbyADR2",
    "outputId": "e65b54fc-d3b7-4ad0-d3ff-8d9c24da810b"
   },
   "outputs": [],
   "source": "plt.figure(figsize=(10, 6))\nplt.subplot(1, 2, 1)\nplt.bar(im_small + 0.05, d_lambda, width=0.10, color=color_spec[2], edgecolor='black')\nplt.axis([0, 1, 0, 0.05])\n# plt.text(-0.1, -0.07, '(a)', transform=plt.gca().transAxes, verticalalignment='center')\nplt.xlabel(axis_label)\nplt.ylabel('$\\Delta \\lambda_i$')\n\nplt.subplot(1, 2, 2)\nx_fine = np.arange(0.01, 1.01, 0.01)\nlambda_fine = np.exp(interp1d(np.log(x), np.log(lambda_['x']), kind='linear', fill_value='extrapolate')(np.log(x_fine)))\nd_lambda_fine = -np.diff(np.concatenate((lambda_fine, [0])))\nplt.bar(x_fine + 0.005, d_lambda_fine, width=0.008, color=color_spec[2],edgecolor='black')\nplt.axis([0, 1, 0, 0.008])\nplt.xlabel(axis_label)\nplt.ylabel('$\\Delta \\lambda_i$')\n\nplt.tight_layout()"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "executionInfo": {
     "elapsed": 1487,
     "status": "ok",
     "timestamp": 1725990513590,
     "user": {
      "displayName": "Jack Wesley Baker",
      "userId": "04310741851728712835"
     },
     "user_tz": 420
    },
    "id": "nSPf0M7IBIac",
    "outputId": "0336d52b-12cd-43f1-c4df-7f825f9e897d"
   },
   "outputs": [],
   "source": "# Summary plot\nplt.figure()\nh1 = plt.loglog(x, lambda_['x'], '-', linewidth=2, color=color_spec[0], label='Original hazard curve')\nplt.plot(im_targ, rate_targ, 'ok')\nh2 = plt.plot(x, lambda_power_law, '-', linewidth=2, color=color_spec[2], label='Fitted power-law hazard curve')\nplt.plot([0.01, im_targ, im_targ], [rate_targ, rate_targ, 1e-10], ':k', linewidth=1)\nplt.text(im_targ * 1.05, rate_targ * 1.5, f'$\\lambda$({im_label} > {im_targ:.3g} g) = {rate_targ:.3g}')\nplt.text(0.01 * 1.05, lambda_m[0] * 1.25, f'$\\Sigma_i \\lambda(rup_i)$ = {lambda_m[0]}')\n\nplt.legend(handles=[h1[0], h2[0]])\nplt.xlabel(axis_label)\nplt.ylabel('Annual rate of exceedance, $\\lambda$')\nplt.xlim([0.01,2])\nplt.ylim([10e-6,10e-2])\nplt.xticks([0.05, 0.1, 0.5, 1, 2], ['0.05', '0.1', '0.5', '1', '2'])\nplt.show()"
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}